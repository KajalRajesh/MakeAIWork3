{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ad54650-17d0-4188-affd-da6efbc7dc97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (0.27.8)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (from requests>=2.20->openai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (from requests>=2.20->openai) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\makeaiwork3\\env\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3ad8c31-4530-4ae3-b1f1-383e8693dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcf1298f-2515-41c6-828d-f78c588dee04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Lenovo/.cache\\torch\\hub\\pytorch_vision_main\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# Imports for Interface\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk, messagebox\n",
    "\n",
    "# Check if GUI is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Constants and hyperparameters\n",
    "num_classes = 4\n",
    "image_size = 224\n",
    "batch_size = 64\n",
    "apples_quantity = 300\n",
    "\n",
    "if num_classes == 2:\n",
    "    if device == torch.device('cuda'):\n",
    "        test_dir_resnet = \"./../Saving model and weight/Resnet_GUI_Class_2.pth\"\n",
    "        test_dir_team = \"./../Saving model and weight/TeamModel_GUI_Class_2.pth\"\n",
    "    else:\n",
    "        test_dir_resnet = \"./../Saving model and weight/Resnet_CPU_Class_2.pth\"\n",
    "        test_dir_team = \"./../Saving model and weight/TeamModel_CPU_Class_2.pth\"\n",
    "    test_dir_data = \"./../Dataset/Test_class_2\"\n",
    "    classes = ('0', '1')\n",
    "else:\n",
    "    if device == torch.device('cuda'):\n",
    "        test_dir_resnet = \"./../Saving model and weight/Resnet_GUI_Class_4.pth\"\n",
    "        test_dir_team = \"./../Saving model and weight/TeamModel_GUI_Class_4.pth\"\n",
    "    else:\n",
    "        test_dir_resnet = \"./../Saving model and weight/Resnet_CPU_Class_4.pth\"\n",
    "        test_dir_team = \"./../Saving model and weight/TeamModel_CPU_Class_4.pth\"\n",
    "    test_dir_data = \"./../Dataset/Test_class_4\"\n",
    "    classes = ('0', '1', '2', '3')\n",
    "    \n",
    "# Load the pre-trained ResNet model\n",
    "model_resnet = torch.hub.load(\"pytorch/vision\", \"resnet18\" , weights=\"IMAGENET1K_V1\")\n",
    "num_features = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Linear(num_features, num_classes)\n",
    "model_resnet = model_resnet.to(device)\n",
    "model_resnet.load_state_dict(torch.load(test_dir_resnet))\n",
    "model_resnet.eval()\n",
    "\n",
    "# Load the pre-trained Team model\n",
    "model_team = torch.load(test_dir_team)\n",
    "model_team = model_team.to(device)\n",
    "model_team.eval()\n",
    "\n",
    "# Define the transformations for test data\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load the test dataset\n",
    "test_dir = test_dir_data\n",
    "test_dataset = ImageFolder(test_dir, transform=transform_test)\n",
    "\n",
    "# Reduce the test dataset to a random sample of apples_quantity examples\n",
    "test_dataset = random.sample(list(test_dataset), k=apples_quantity)\n",
    "\n",
    "# Create a DataLoader for managing the test data batches\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def get_model(data_loader, model):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    # Iterate over the test data and make predictions for ResNet and Team model\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(inputs)\n",
    "        output = torch.argmax(torch.exp(output), dim=1).cpu().numpy()\n",
    "        y_pred.extend(output)\n",
    "        labels = labels.cpu().numpy()\n",
    "        y_true.extend(labels)\n",
    "    \n",
    "    return y_pred, y_true\n",
    "\n",
    "y_pred_resnet, y_true_resnet = get_model(test_loader, model_resnet)\n",
    "y_pred_team, y_true_team = get_model(test_loader, model_team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c67442c9-c254-411c-908a-c39d7dcbe7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty lists to store the predicted labels and true labels\n",
    "predicted_labels_resnet = []\n",
    "true_labels_resnet = []\n",
    "\n",
    "predicted_labels_team = []\n",
    "true_labels_team = []\n",
    "\n",
    "test_loss_resnet = 0.0\n",
    "test_loss_team = 0.0\n",
    "correct_resnet = 0\n",
    "correct_team = 0\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Disable gradient calculation\n",
    "with torch.no_grad():\n",
    "    # Set the models to evaluation mode\n",
    "    model_resnet.eval()\n",
    "    model_team.eval()\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass for resnet18 model\n",
    "        outputs_resnet = model_resnet(images)\n",
    "        _, predicted_resnet = torch.max(outputs_resnet, 1)\n",
    "        \n",
    "        # Calculate loss for resnet18 model\n",
    "        loss_resnet = criterion(outputs_resnet, labels)\n",
    "        test_loss_resnet += loss_resnet.item()\n",
    "        \n",
    "        # Update the counts for correct predictions for resnet18 model\n",
    "        correct_resnet += (predicted_resnet == labels).sum().item()\n",
    "        \n",
    "        # Append predicted and true labels for resnet18 model\n",
    "        predicted_labels_resnet.extend(predicted_resnet.cpu().numpy())\n",
    "        true_labels_resnet.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Forward pass for team model\n",
    "        outputs_team = model_team(images)\n",
    "        _, predicted_team = torch.max(outputs_team, 1)\n",
    "        \n",
    "        # Calculate loss for team model\n",
    "        loss_team = criterion(outputs_team, labels)\n",
    "        test_loss_team += loss_team.item()\n",
    "        \n",
    "        # Update the counts for correct predictions for team model\n",
    "        correct_team += (predicted_team == labels).sum().item()\n",
    "        \n",
    "        # Append predicted and true labels for team model\n",
    "        predicted_labels_team.extend(predicted_team.cpu().numpy())\n",
    "        true_labels_team.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate the average test losses\n",
    "test_loss_resnet /= len(test_loader)\n",
    "test_loss_team   /= len(test_loader)\n",
    "\n",
    "# Calculate the test accuracies\n",
    "accuracy_resnet = correct_resnet / len(test_dataset)\n",
    "accuracy_team   = correct_team / len(test_dataset)\n",
    "\n",
    "# Make resnet and Team model test accuracy and test loss\n",
    "resnet_test_accuracy = \"{:.2f}%\".format(accuracy_resnet * 100)\n",
    "resnet_test_loss     = \"{:.4f}\".format(test_loss_resnet)\n",
    "team_test_accuracy   = \"{:.2f}%\".format(accuracy_team * 100)\n",
    "team_test_loss       = \"{:.4f}\".format(test_loss_team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf7c895-dbe3-4ead-aa60-5e3b885407f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for error message box\n",
    "def show_error(error_message):\n",
    "    messagebox.showerror('Input Error', f'Error: {error_message}')\n",
    "    \n",
    "def calculate_bad_apple_percentage(sample, num_classes):\n",
    "    if num_classes == 2:\n",
    "        blotch_apples = 0\n",
    "        normal_apples = sample.count(1)\n",
    "        rotten_apples = sample.count(2)\n",
    "        scab_apples   = 0\n",
    "        return ((rotten_apples + blotch_apples + scab_apples) / len(sample)) * 100\n",
    "    else:\n",
    "        blotch_apples = sample.count(0)\n",
    "        normal_apples = sample.count(1)\n",
    "        rotten_apples = sample.count(2)\n",
    "        scab_apples   = sample.count(3)\n",
    "        return ((rotten_apples + blotch_apples + scab_apples) / len(sample)) * 100\n",
    "\n",
    "\n",
    "def classify_batch(perc_bad_apples, aql):\n",
    "    if perc_bad_apples <= aql:\n",
    "        return 'Class 1: Supermarket'\n",
    "    elif aql < perc_bad_apples < 6.5:\n",
    "        return 'Class 2: Apple sauce factory'\n",
    "    elif 6.5 <= perc_bad_apples < 15:\n",
    "        return 'Class 3: Apple syrup factory'\n",
    "    else:\n",
    "        return 'Class 4: Feed them to the pigs!'\n",
    "\n",
    "\n",
    "def generate_pie_chart(sizes, labels, title, filename):\n",
    "    plt.clf()\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "    plt.axis('equal')\n",
    "    plt.title(title)\n",
    "    plt.savefig(filename)\n",
    "\n",
    "\n",
    "def calculate():\n",
    "    try:\n",
    "        # Get input from user\n",
    "        batch_size = int(batch_size_2.get())\n",
    "        sample_size = int(sample_size_2.get())\n",
    "        number_of_runs = int(nr_runs.get())\n",
    "        aql = float(user_aql.get())\n",
    "\n",
    "        # Make limit for inputs\n",
    "        if not 100 <= batch_size <= len(y_pred_resnet):\n",
    "            show_error(f'Batch size must be between 250 to {len(y_pred_resnet)}')\n",
    "            return\n",
    "        if not 5 <= sample_size <= 100:\n",
    "            show_error('Sample size must be between 5 to 100')\n",
    "            return\n",
    "        if not 1 <= number_of_runs <= 100:\n",
    "            show_error('Number of runs must be between 1 to 50')\n",
    "            return\n",
    "        if not 0 < aql < 100:\n",
    "            show_error('Your AQL must be between 1 to 100')\n",
    "            return\n",
    "        if sample_size * number_of_runs > batch_size:\n",
    "            show_error(\"The multiplication of 'sample size' and 'run number' must be less than 'batch size'\")\n",
    "            return\n",
    "\n",
    "        # Generate random indices for batch size and sample size\n",
    "        random.seed(f'{time.time()/200:.1f}')\n",
    "        random_numbers_batch = random.sample(range(len(y_pred_resnet)), batch_size)\n",
    "        random_numbers_sample = random.sample(range(len(random_numbers_batch)), (sample_size * number_of_runs))\n",
    "\n",
    "        # Create batch size with batch index and y_pred\n",
    "        batch_size_resnet = [y_pred_resnet[index] for index in random_numbers_batch]\n",
    "        batch_size_team = [y_pred_team[index] for index in random_numbers_batch]\n",
    "\n",
    "        # Create sample size with sample index and batch size\n",
    "        sample_resnet = [batch_size_resnet[index] for index in random_numbers_sample]\n",
    "        sample_team = [batch_size_team[index] for index in random_numbers_sample]\n",
    "\n",
    "        # Calculate the percentage of bad apples for ResNet model\n",
    "        perc_bad_apples_resnet = calculate_bad_apple_percentage(sample_resnet, num_classes)\n",
    "\n",
    "        # Classify the batch based on the percentage of bad apples for ResNet model\n",
    "        answer_resnet = classify_batch(perc_bad_apples_resnet, aql)\n",
    "\n",
    "        # Calculate the percentage of bad apples for Team model\n",
    "        perc_bad_apples_team = calculate_bad_apple_percentage(sample_team, num_classes)\n",
    "\n",
    "        # Classify the batch based on the percentage of bad apples for Team model\n",
    "        answer_team = classify_batch(perc_bad_apples_team, aql)\n",
    "\n",
    "        # Generate pie chart for ResNet model\n",
    "        sizes_resnet = [sample_resnet.count(i) for i in range(num_classes)]\n",
    "        labels_resnet = ['Class ' + str(i) for i in range(1, num_classes+1)]\n",
    "        generate_pie_chart(sizes_resnet, labels_resnet, 'Distribution of Apple Types by resnet18 in samples', './pie_chart_resnet.png')\n",
    "\n",
    "        # Generate pie chart for Team model\n",
    "        sizes_team = [sample_team.count(i) for i in range(num_classes)]\n",
    "        labels_team = ['Class ' + str(i) for i in range(1, num_classes+1)]\n",
    "        generate_pie_chart(sizes_team, labels_team, 'Distribution of Apple Types by team model in samples', './pie_chart_team.png')\n",
    "\n",
    "        # Update interface with results for ResNet model\n",
    "        good_apple_percentage_resnet.set(f\"{(100 - perc_bad_apples_resnet):.2f} %\")\n",
    "        test_accuracy_resnet.set(f\"{resnet_test_accuracy} %\")\n",
    "        test_loss_resnet.set(f\"{resnet_test_loss} %\")\n",
    "        group_apple_category_resnet.set(answer_resnet)\n",
    "\n",
    "        # Update interface with results for Team model\n",
    "        good_apple_percentage_team.set(f\"{(100 - perc_bad_apples_team):.2f} %\")\n",
    "        test_accuracy_team.set(f\"{team_test_accuracy} %\")\n",
    "        test_loss_team.set(f\"{team_test_loss} %\")\n",
    "        group_apple_category_team.set(answer_team)\n",
    "\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "# Function for chatbot GPT\n",
    "def gpt_chatbot():\n",
    "    try:\n",
    "        # Get input from user\n",
    "        batch_size = int(batch_size_2.get())\n",
    "        sample_size = int(sample_size_2.get())\n",
    "        number_of_runs = int(nr_runs.get())\n",
    "        aql = float(user_aql.get())\n",
    "        \n",
    "        # Set variables for chat bot\n",
    "        good = 'Normal'\n",
    "        bad  = 'Rot + Blotch + Scab'\n",
    "        sauce_factory_aql = 6.5\n",
    "        syrup_factory_aql = 15\n",
    "        \n",
    "        # Generate random indices for batch size and sample size\n",
    "        random.seed(f'{time.time()/200:.1f}')\n",
    "        random_numbers_batch  = random.sample(range(len(y_pred_resnet)), batch_size)\n",
    "        random_numbers_sample = random.sample(range(len(random_numbers_batch)), (sample_size * number_of_runs))\n",
    "\n",
    "        # Create batch size with batch index and y_pred\n",
    "        batch_size_resnet = [y_pred_resnet[index] for index in random_numbers_batch]\n",
    "\n",
    "        # Create sample size with sample index and batch size\n",
    "        samples_resnet = [batch_size_resnet[index] for index in random_numbers_sample]\n",
    "        \n",
    "        # Calculate the percentage of bad apples for 2 classes\n",
    "        if num_classes == 2:\n",
    "            # for ResNet\n",
    "            Blotch_Apple_resnet_batch = 0\n",
    "            Normal_Apple_resnet_batch = batch_size_resnet.count(0)\n",
    "            Rot_Apple_resnet_batch    = batch_size_resnet.count(1)\n",
    "            Scab_Apple_resnet_batch   = 0\n",
    "            Blotch_Apple_resnet_samples  = 0\n",
    "            Normal_Apple_resnet_samples  = samples_resnet.count(0)\n",
    "            Rot_Apple_resnet_samples     = samples_resnet.count(1)\n",
    "            Scab_Apple_resnet_samples    = 0\n",
    "            \n",
    "        else:\n",
    "            # for ResNet\n",
    "            Blotch_Apple_resnet_batch = batch_size_resnet.count(0)\n",
    "            Normal_Apple_resnet_batch = batch_size_resnet.count(1)\n",
    "            Rot_Apple_resnet_batch    = batch_size_resnet.count(2)\n",
    "            Scab_Apple_resnet_batch   = batch_size_resnet.count(3)\n",
    "            Blotch_Apple_resnet_samples  = samples_resnet.count(0)\n",
    "            Normal_Apple_resnet_samples  = samples_resnet.count(1)\n",
    "            Rot_Apple_resnet_samples     = samples_resnet.count(2)\n",
    "            Scab_Apple_resnet_samples    = samples_resnet.count(3)\n",
    "             \n",
    "        number_of_bad_apples_resnet_batch   = (Rot_Apple_resnet_batch + Blotch_Apple_resnet_batch + Scab_Apple_resnet_batch)\n",
    "        number_of_bad_apples_resnet_samples = (Rot_Apple_resnet_samples + Blotch_Apple_resnet_samples + Scab_Apple_resnet_samples)\n",
    " \n",
    "        # Chat GPT function\n",
    "        def chat_with_gpt3(prompt):\n",
    "            response = openai.Completion.create(\n",
    "                engine='text-davinci-003',\n",
    "                prompt=prompt,\n",
    "                max_tokens=50,\n",
    "                temperature=0.7,\n",
    "                n=1,\n",
    "                stop=None\n",
    "            )\n",
    "            if len(response.choices) > 0:\n",
    "                return response.choices[0].text.strip()\n",
    "            return \"\"\n",
    "        \n",
    "        # Make initial information for chat bot\n",
    "        initial_prompt = f\"Batch size: {batch_size}\\nSamples size: {sample_size*number_of_runs}\\nSupermarket Aql: {aql}\\nsyrup factory Aql: {syrup_factory_aql}\\nsauce factory Aql: {sauce_factory_aql}\\nBlotch in batch: {Blotch_Apple_resnet_batch}\\nScab in batch: {Scab_Apple_resnet_batch}\\nRot in batch: {Rot_Apple_resnet_batch}\\nNormal in batch: {Normal_Apple_resnet_batch}\\nBlotch in samples: {Blotch_Apple_resnet_samples}\\nScab in samples: {Scab_Apple_resnet_samples}\\nRot in samples: {Rot_Apple_resnet_samples}\\nNormal in samples: {Normal_Apple_resnet_samples}\\nGood: {good}\\nBad: {bad}\\nBad in batch: {number_of_bad_apples_resnet_batch}\\nBad in samples: {number_of_bad_apples_resnet_samples}\\nHossein bot:\"\n",
    "\n",
    "        # Get user question and send it to chat GPT function\n",
    "        user_input = chat_bot_box.get()\n",
    "        if user_input.lower() == \"exit\":\n",
    "            bot_response = \"Goodbye!\"\n",
    "        else:\n",
    "            chat_prompt  = f'{initial_prompt} {user_input}\\n'\n",
    "            bot_response = chat_with_gpt3(chat_prompt)\n",
    "        \n",
    "        # Send bot response to interface\n",
    "        gpt_bot_answer.set(f\"GPT bot :  {bot_response}.\")\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "# Function for chatbot Team model\n",
    "def team_chatbot():\n",
    "    try:\n",
    "        # Get input from user\n",
    "        batch_size = int(batch_size_2.get())\n",
    "        sample_size = int(sample_size_2.get())\n",
    "        number_of_runs = int(nr_runs.get())\n",
    "        aql = float(user_aql.get())\n",
    "\n",
    "        # Set variables for chat bot\n",
    "        good = 'Normal'\n",
    "        bad = 'Rot + Blotch + Scab'\n",
    "        sauce_factory_aql = 6.5\n",
    "        syrup_factory_aql = 15\n",
    "\n",
    "        # Generate random indices for batch size and sample size\n",
    "        random.seed(f'{time.time() / 200:.1f}')\n",
    "        random_numbers_batch = random.sample(range(len(y_pred_team)), batch_size)\n",
    "        random_numbers_sample = random.sample(range(len(random_numbers_batch)), (sample_size * number_of_runs))\n",
    "\n",
    "        # Create batch size with batch index and y_pred\n",
    "        batch_size_team = [y_pred_team[index] for index in random_numbers_batch]\n",
    "\n",
    "        # Create sample size with sample index and batch size\n",
    "        samples_team = [batch_size_team[index] for index in random_numbers_sample]\n",
    "\n",
    "        # Calculate the percentage of bad apples for 2 classes\n",
    "        if num_classes == 2:\n",
    "            # for team\n",
    "            Blotch_Apple_team_batch = 0\n",
    "            Normal_Apple_team_batch = batch_size_team.count(0)\n",
    "            Rot_Apple_team_batch = batch_size_team.count(1)\n",
    "            Scab_Apple_team_batch = 0\n",
    "            Blotch_Apple_team_samples = 0\n",
    "            Normal_Apple_team_samples = samples_team.count(0)\n",
    "            Rot_Apple_team_samples = samples_team.count(1)\n",
    "            Scab_Apple_team_samples = 0\n",
    "\n",
    "        else:\n",
    "            # for team\n",
    "            Blotch_Apple_team_batch = batch_size_team.count(0)\n",
    "            Normal_Apple_team_batch = batch_size_team.count(1)\n",
    "            Rot_Apple_team_batch = batch_size_team.count(2)\n",
    "            Scab_Apple_team_batch = batch_size_team.count(3)\n",
    "            Blotch_Apple_team_samples = samples_team.count(0)\n",
    "            Normal_Apple_team_samples = samples_team.count(1)\n",
    "            Rot_Apple_team_samples = samples_team.count(2)\n",
    "            Scab_Apple_team_samples = samples_team.count(3)\n",
    "\n",
    "        number_of_bad_apples_team_batch = (\n",
    "                    Rot_Apple_team_batch + Blotch_Apple_team_batch + Scab_Apple_team_batch)\n",
    "        number_of_bad_apples_team_samples = (\n",
    "                    Rot_Apple_team_samples + Blotch_Apple_team_samples + Scab_Apple_team_samples)\n",
    "\n",
    "        # Load the pre-trained sentence transformer model\n",
    "        model = SentenceTransformer('all-MiniLM-L12-v2')\n",
    "\n",
    "        # Define a dictionary of questions and answers\n",
    "        qa_pairs = {\n",
    "            \"can you tell me the total number of apples in the batch?\": f\"The total number of apples in the batch is {len(batch_size_team)}.\",\n",
    "            \"can you tell me the total number of apples in the samples?\": f\"The total number of apples in the batch is {len(samples_team)}.\",\n",
    "            \"can you tell me the total number of good apples in the batch?\": f\"The total number of apples in the batch is {Normal_Apple_team_batch}.\",\n",
    "            \"can you tell me the total number of good apples in the samples?\": f\"The total number of apples in the batch is {Normal_Apple_team_samples}.\",\n",
    "            \"can you tell me the total number of bad apples in the batch?\": f\"The total number of apples in the batch is {number_of_bad_apples_team_batch}.\",\n",
    "            \"can you tell me the total number of bad apples in the samples?\": f\"The total number of apples in the batch is {number_of_bad_apples_team_samples}.\",\n",
    "            \"how many good apples are in the batch?\": f\"The number of good apples in the batch is {Normal_Apple_team_batch}.\",\n",
    "            \"how many good apples are in the samples?\": f\"The number of good apples in the samples is {Normal_Apple_team_samples}.\",\n",
    "            \"how many bad apples are in the batch?\": f\"The number of bad apples in the batch is {number_of_bad_apples_team_batch}.\",\n",
    "            \"how many bad apples are in the samples?\": f\"The number of bad apples in the samples is {number_of_bad_apples_team_samples}.\",\n",
    "            \"what is the percentage of bad apples in the batch?\": f\"The percentage of bad apples is {number_of_bad_apples_team_batch / len(batch_size_team) * 100:.2f}%.\",\n",
    "            \"what is the percentage of bad apples in the samples?\": f\"The percentage of bad apples is {number_of_bad_apples_team_samples / len(samples_team) * 100:.2f}%.\",\n",
    "            \"how many bad apples are there in an approved batch?\": f\"The number of bad apples in an approved batch size of {len(batch_size_team)} is {number_of_bad_apples_team_batch}.\",\n",
    "            \"how many bad apples are there in an approved samples?\": f\"The number of bad apples in an approved batch size of {len(samples_team)} is {number_of_bad_apples_team_samples}.\",\n",
    "            \"how many apples are categorized as blotch in the batch?\": f\"The number of apples categorized as blotch is {Blotch_Apple_team_batch}.\",\n",
    "            \"how many apples are categorized as blotch in the samples?\": f\"The number of apples categorized as blotch is {Blotch_Apple_team_samples}.\",\n",
    "            \"what is the proportion of rotten apples in the batch?\": f\"The proportion of rotten apples is {Rot_Apple_team_batch / len(batch_size_team):.2f}.\",\n",
    "            \"what is the proportion of rotten apples in the samples?\": f\"The proportion of rotten apples is {Rot_Apple_team_samples / len(samples_team):.2f}.\",\n",
    "            \"can we use this apple batch to Apple sauce factory?\": f\"Upon evaluation {'Yes, we can send this apple batch to Apple sauce factory.' if aql <= number_of_bad_apples_team_samples / len(samples_team) * 100 < 6.5 else 'No, there are not enough healthy apples.'}\",\n",
    "            \"are there enough healthy apples to Apple syrup factory?\": f\"Upon evaluation {'Yes, there are enough healthy apples.' if 6.5 <= number_of_bad_apples_team_samples / len(samples_team) * 100 < 15 else 'No, there are not enough healthy apples.'}\",\n",
    "            \"can we use this batch for the supermarket if the acceptance quality is increased by 1 percentage for the klasse 1?\": f\" {'Yes, it can be send to supermarket.' if number_of_bad_apples_team_samples / len(samples_team) * 100 <= aql + 1 else 'Even if the acceptance quality is increased by 1, it cannot be used in supermarket'}\",\n",
    "            \"does the quality of the batch increase when the batch size is increased?\": \"The quality of the batch may or may not increase when the batch size is increased. It depends on various factors.\",\n",
    "            \"whatâ€™s the average ratio between the healthy and unhealthy apples for different sample sizes?\": f\"The average ratio between healthy and unhealthy apples is {Normal_Apple_team_samples / number_of_bad_apples_team_samples}.\",\n",
    "        }\n",
    "\n",
    "        # Calculate sentence embeddings for the questions\n",
    "        question_embeddings = model.encode(list(qa_pairs.keys()))\n",
    "\n",
    "\n",
    "        def get_fallback_answer():\n",
    "            return \"I'm sorry, but I don't have an answer to that question at the moment.\"\n",
    "        \n",
    "        def get_answer_2(user_query):\n",
    "            query_embedding = model.encode([user_query]).flatten()\n",
    "            similarities = [1 - cosine(query_embedding, q_emb) for q_emb in question_embeddings]\n",
    "            max_similarity = max(similarities)\n",
    "            most_similar_idx = similarities.index(max_similarity)\n",
    "\n",
    "            if max_similarity >= 0.8:\n",
    "                return qa_pairs[list(qa_pairs.keys())[most_similar_idx]]\n",
    "            else:\n",
    "                return get_fallback_answer()\n",
    "        # Chat bot loop\n",
    "        \n",
    "        user_query = chat_bot_box.get().lower()\n",
    "        if user_query == \"exit\":\n",
    "            bot_response = \"Goodbye!\"\n",
    "        else:\n",
    "            chat_prompt = get_answer_2(user_query)\n",
    "            \n",
    "            if chat_prompt is None:\n",
    "                bot_response = get_fallback_answer()\n",
    "            else:   \n",
    "                bot_response = f\"{chat_prompt}.\"        \n",
    "            team_bot_answer.set(f\"Team bot:  {bot_response}.\")\n",
    "        # def get_answer_2(user_query):\n",
    "        #     query_embedding = model.encode([user_query]).flatten()  # Flatten the query_embedding\n",
    "        #     similarities = [1 - cosine(query_embedding, q_emb) for q_emb in question_embeddings]\n",
    "        #     most_similar_idx = similarities.index(max(similarities))\n",
    "        #     return qa_pairs[list(qa_pairs.keys())[most_similar_idx]]\n",
    "\n",
    "\n",
    "        # # Chat bot loop\n",
    "\n",
    "        # user_query = chat_bot_box.get().lower()\n",
    "        # if user_query == \"exit\":\n",
    "        #     bot_response = \"Goodbye!\"\n",
    "        # else:\n",
    "        #     chat_prompt = get_answer_2(user_query)\n",
    "        #     bot_response = f\"{chat_prompt}.\"\n",
    "\n",
    "        # team_bot_answer.set(f\"Team bot:  {bot_response}.\")\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "# Creating method for adding picture\n",
    "def on_click():\n",
    "    global my_img\n",
    "    top = Toplevel()\n",
    "    top.title('pie chart')\n",
    "    my_img = ImageTk.PhotoImage(Image.open('./pie_chart_resnet.png'))\n",
    "    Label(top, image=my_img).pack()\n",
    "    \n",
    "def on_click_1():\n",
    "    global my_img\n",
    "    top = Toplevel()\n",
    "    top.title('pie chart')\n",
    "    my_img = ImageTk.PhotoImage(Image.open('./pie_chart_team.png'))\n",
    "    Label(top, image=my_img).pack()\n",
    "    \n",
    "# Building interface\n",
    "root = Tk()\n",
    "root.title('Apple qualifier')\n",
    "\n",
    "# Font properties\n",
    "s = ttk.Style()\n",
    "font_1 = ('Ariel Nova', 15)\n",
    "s.configure('.', font = font_1)\n",
    "\n",
    "mainframe = ttk.Frame(root, padding='3 3 12 12')\n",
    "mainframe.grid(column=0, row=0, sticky=(N, W, E, S))\n",
    "root.columnconfigure(0, weight=1)\n",
    "root.rowconfigure(0, weight=1)    \n",
    "\n",
    "batch_size_2 = StringVar()\n",
    "batch_size_entry = ttk.Entry(mainframe, width=10, font = font_1, textvariable=batch_size_2)\n",
    "batch_size_entry.grid(column=2, row=1, sticky=(W, E))\n",
    "\n",
    "sample_size_2 = StringVar()\n",
    "sample_size_entry = ttk.Entry(mainframe, width=10, font = font_1, textvariable=sample_size_2)\n",
    "sample_size_entry.grid(column=2, row=2, sticky=(W, E))\n",
    "\n",
    "nr_runs = StringVar()\n",
    "nr_runs_entry = ttk.Entry(mainframe, width=10, font = font_1, textvariable=nr_runs)\n",
    "nr_runs_entry.grid(column=2, row=3, sticky=(W, E))\n",
    "\n",
    "user_aql = StringVar()\n",
    "user_aql_entry = ttk.Entry(mainframe, width=10, font = font_1, textvariable=user_aql)\n",
    "user_aql_entry.grid(column=2, row=4, sticky=(W, E))\n",
    "\n",
    "# Calculating Button (lower right) ResNet model\n",
    "good_apple_percentage_resnet = StringVar()\n",
    "ttk.Label(mainframe, textvariable=good_apple_percentage_resnet).grid(column=2, row=7, sticky=(W, E))\n",
    "\n",
    "test_accuracy_resnet = StringVar()\n",
    "ttk.Label(mainframe, textvariable=test_accuracy_resnet).grid(column=2, row=8, sticky=(W, E))\n",
    "\n",
    "test_loss_resnet = StringVar()\n",
    "ttk.Label(mainframe, textvariable=test_loss_resnet).grid(column=2, row=9, sticky=(W, E))\n",
    "\n",
    "group_apple_category_resnet = StringVar()\n",
    "ttk.Label(mainframe, width=30, textvariable=group_apple_category_resnet).grid(column=2, row=10, sticky=(W, E))\n",
    "\n",
    "# Calculating Button (lower right) Team model\n",
    "good_apple_percentage_team = StringVar()\n",
    "ttk.Label(mainframe, textvariable=good_apple_percentage_team).grid(column=3, row=7, sticky=(W, E))\n",
    "\n",
    "test_accuracy_team = StringVar()\n",
    "ttk.Label(mainframe, textvariable=test_accuracy_team).grid(column=3, row=8, sticky=(W, E))\n",
    "\n",
    "test_loss_team = StringVar()\n",
    "ttk.Label(mainframe, textvariable=test_loss_team).grid(column=3, row=9, sticky=(W, E))\n",
    "\n",
    "group_apple_category_team = StringVar()\n",
    "ttk.Label(mainframe, width=30, textvariable=group_apple_category_team).grid(column=3, row=10, sticky=(W, E))\n",
    "\n",
    "# Chatbot box\n",
    "chat_bot_box = StringVar()\n",
    "chat_bot_box_entry = ttk.Entry(mainframe, width=60, font = font_1, textvariable=chat_bot_box)\n",
    "chat_bot_box_entry.grid(column=1, row=12, sticky=(W, E))\n",
    "\n",
    "gpt_bot_answer = StringVar()\n",
    "ttk.Label(mainframe, textvariable=gpt_bot_answer).grid(column=1, row=13, sticky=(W, E))\n",
    "\n",
    "team_bot_answer = StringVar()\n",
    "ttk.Label(mainframe, textvariable=team_bot_answer).grid(column=1, row=14, sticky=(W, E))\n",
    "\n",
    "# Building interface Buttons\n",
    "ttk.Button(mainframe, text='Info', command=on_click).grid(column=3, row=1, sticky=W)\n",
    "ttk.Button(mainframe, text='Info', command=on_click).grid(column=3, row=2, sticky=W)\n",
    "ttk.Button(mainframe, text='Info', command=on_click).grid(column=3, row=3, sticky=W)\n",
    "ttk.Button(mainframe, text='Info', command=on_click).grid(column=3, row=4, sticky=W)\n",
    "ttk.Button(mainframe, text='Run           ', command=calculate).grid(column=2, row=5, sticky=W)\n",
    "ttk.Button(mainframe, text='Chart ResNet18', command=on_click).grid(column=2, row=11, sticky=W)\n",
    "ttk.Button(mainframe, text='Chart Team    ', command=on_click_1).grid(column=3, row=11, sticky=W)\n",
    "ttk.Button(mainframe, text='Chat GPT bot  ', command=gpt_chatbot).grid(column=2, row=12, sticky=W)\n",
    "ttk.Button(mainframe, text='Team chat bot ', command=team_chatbot).grid(column=3, row=12, sticky=W)\n",
    "\n",
    "# Information Labels for Input Data Buttons\n",
    "ttk.Label(mainframe, text=f\"Batch Size (100-{len(y_pred_resnet)}): \").grid(column=1, row=1, sticky=W)\n",
    "ttk.Label(mainframe, text=\"Sample Size (5-100):       \").grid(column=1, row=2, sticky=W)\n",
    "ttk.Label(mainframe, text=\"Number of Runs (1-100):    \").grid(column=1, row=3, sticky=W)\n",
    "ttk.Label(mainframe, text=\"Your AQL (1-100):          \").grid(column=1, row=4, sticky=W)\n",
    "ttk.Label(mainframe, text=\"The good apples percentage:\").grid(column=1, row=7, sticky=W)\n",
    "ttk.Label(mainframe, text=\"The test accuracy:         \").grid(column=1, row=8, sticky=W)\n",
    "ttk.Label(mainframe, text=\"The test loss:             \").grid(column=1, row=9, sticky=W)\n",
    "ttk.Label(mainframe, text=\"The apple category:        \").grid(column=1, row=10, sticky=W)\n",
    "ttk.Label(mainframe, text=\"Please ask me a question:  \").grid(column=1, row=11, sticky=W)\n",
    "ttk.Label(mainframe, text=\"Resnet18  \").grid(column=2, row=6, sticky=W)\n",
    "ttk.Label(mainframe, text=\"Team model\").grid(column=3, row=6, sticky=W)\n",
    "\n",
    "# Interface INPUT loop and OUTPUT\n",
    "for child in mainframe.winfo_children(): \n",
    "    child.grid_configure(padx=18, pady=9)    \n",
    "    \n",
    "batch_size_entry.focus()\n",
    "sample_size_entry.focus()\n",
    "nr_runs_entry.focus()\n",
    "user_aql_entry.focus()\n",
    "chat_bot_box_entry.focus()\n",
    "\n",
    "root.bind('<Return>', calculate)\n",
    "root.bind('<Return>', gpt_chatbot)\n",
    "root.bind('<Return>', team_chatbot)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc721d1-389a-4547-84af-e20645669096",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4325af5-4382-4f81-9c0e-449793e18bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
