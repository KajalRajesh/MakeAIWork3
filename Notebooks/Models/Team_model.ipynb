{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758bb418-5288-4ab9-bae2-312ddef18aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hossein/miniconda3/envs/miw/lib/python3.11/site-packages/torch/cuda/__init__.py:107: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch 1/1: Train Loss: 587.8877, Test Loss: 0.9144, Train Accuracy: 45.31%, Val Accuracy: 64.88%, Test Accuracy: 62.50%\n",
      "2023-06-26 12:36:25\n",
      "Total duration: 00:02:04\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.io import ImageReadMode\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Check if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Define constants\n",
    "image_size = 224\n",
    "batch_size = 64\n",
    "num_epochs = 1\n",
    "learning_rate = 0.1\n",
    "num_classes = 4         # Define num_classes 2 if you want to use dataset with 2 classes\n",
    "dropout = 0.5\n",
    "start_time = time.time()\n",
    "\n",
    "# Function to read directories and label images\n",
    "def label_images_in_directories(main_directory):\n",
    "    label_names = []\n",
    "    image_files = []\n",
    "    for directory in os.listdir(main_directory):\n",
    "        sub_directory = os.path.join(main_directory, directory)\n",
    "        if os.path.isdir(sub_directory):\n",
    "            for filename in os.listdir(sub_directory):\n",
    "                image_file = os.path.join(sub_directory, filename)\n",
    "                if os.path.isfile(image_file) and filename.endswith(\".jpg\"):\n",
    "                    label_names.append(directory)\n",
    "                    image_files.append(image_file)\n",
    "\n",
    "    image_tensors = [torchvision.io.read_image(image, mode=ImageReadMode.UNCHANGED).to(torch.float32)/255 for image in image_files]\n",
    "    nr_of_images = len(image_tensors)\n",
    "\n",
    "    return label_names, image_tensors\n",
    "\n",
    "# Load and label the images in the training directory\n",
    "if num_classes == 2:\n",
    "    train_dir_data = \"./../Dataset/Train_class_2\"\n",
    "else:\n",
    "    train_dir_data = \"./../Dataset/Train_class_4\"\n",
    "\n",
    "label_names, image_tensors = label_images_in_directories(train_dir_data)\n",
    "\n",
    "\n",
    "# Define the transformations for train data before entering the neural network\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.RandomCrop(size=image_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Define the transformations for test data before entering the neural network\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),                     # Resize images to 224x224 pixels\n",
    "    transforms.ToTensor(),                                           # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the images\n",
    "])\n",
    "\n",
    "# Create DataLoaders for training, validation, and test datasets\n",
    "train_dataset = ImageFolder(train_dir_data, transform=transform_train)\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "dataset_size = len(train_dataset)\n",
    "train_size = int(train_ratio * dataset_size)\n",
    "val_size = int(val_ratio * dataset_size)\n",
    "test_size = dataset_size - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    train_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders for managing the data batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes, image_size_nn, dropout):\n",
    "        super().__init__()\n",
    "        self.CNN_Apple = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            \n",
    "            nn.Linear(32 * 56 * 56, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = self.CNN_Apple(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the model\n",
    "image_size_nn = int(image_size/4)\n",
    "model = CNNModel(num_classes, image_size_nn, dropout)\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function, optimizer, and learning rate scheduler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = ReduceLROnPlateau(optimizer, patience=2)\n",
    "\n",
    "# Training function\n",
    "def train(model, criterion, optimizer, train_loader, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    accuracy = 100.0 * correct / total\n",
    "    return running_loss / len(train_loader), accuracy\n",
    "\n",
    "# Test function for validation and test sets\n",
    "def test(model, criterion, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return running_loss / len(loader), accuracy\n",
    "\n",
    "# Initialize the best loss variable with infinity\n",
    "best_loss = float('inf')\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_accuracy = train(model, criterion, optimizer, train_loader, device)\n",
    "    test_loss, test_accuracy = test(model, criterion, test_loader, device)\n",
    "    val_loss, val_accuracy = test(model, criterion, val_loader, device)\n",
    "    scheduler.step(test_loss) \n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Val Accuracy: {val_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%')\n",
    "    \n",
    "    # Save model\n",
    "    if num_classes == 2:\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            with open(\"./../TeamModel_2classes.pth\", 'wb') as f:\n",
    "                torch.save(model.CNN_Apple , f)\n",
    "    else:\n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            with open(\"./../TeamModel_4classes.pth\", 'wb') as f:\n",
    "                torch.save(model.CNN_Apple , f) \n",
    "\n",
    "# Set a time and date\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(timestamp)\n",
    "\n",
    "duration = time.time() - start_time\n",
    "duration_str = time.strftime(\"%H:%M:%S\", time.gmtime(duration))\n",
    "print(f\"Total duration: {duration_str}\")\n",
    "        \n",
    "data = {\n",
    "    \"Timestamp\": timestamp,\n",
    "    \"Duration\": duration_str,\n",
    "    \"Model type\": \"Team model\",\n",
    "    \"Dataset use\": os.path.basename(train_dir_data),\n",
    "    \"Image Resize\": str(image_size)+\"*\"+str(image_size),\n",
    "    \"Epochs\": num_epochs,\n",
    "    \"Learning rate\": learning_rate,\n",
    "    \"Batch size\": batch_size,\n",
    "    \"Train Accuracy\": f\"{train_accuracy:.2f}\",\n",
    "    \"Validation accuracy\": f\"{val_accuracy:.2f}\",\n",
    "    \"Test Accuracy\": f\"{test_accuracy:.2f}\",\n",
    "}\n",
    "# Check if the CSV file already exists\n",
    "if os.path.isfile(\"model_data.csv\"):\n",
    "    existing_data = pd.read_csv(\"model_data.csv\")\n",
    "    new_data = pd.concat([existing_data, pd.DataFrame(data, index=[0])], ignore_index=True)\n",
    "else:\n",
    "    new_data = pd.DataFrame(data, index=[0])\n",
    "\n",
    "# Save the updated DataFrame to CSV\n",
    "new_data.to_csv(\"model_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be58865-5f42-44a7-8c83-3bb32804bb1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
