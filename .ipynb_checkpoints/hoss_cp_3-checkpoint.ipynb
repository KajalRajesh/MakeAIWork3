{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96067783-dbf2-44dc-86f0-c9c0d6a90a2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cv2\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from cv2 import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, default_collate\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "def label_images_in_directories(main_directory):\n",
    "    label_names = []\n",
    "    image_files = []\n",
    "    for directory in os.listdir(main_directory):\n",
    "        sub_directory = os.path.join(main_directory, directory)\n",
    "        if os.path.isdir(sub_directory):\n",
    "            for filename in os.listdir(sub_directory):\n",
    "                image_file = os.path.join(sub_directory, filename)\n",
    "                if os.path.isfile(image_file) and filename.endswith(\".jpg\"):\n",
    "                    label_names.append(directory)\n",
    "                    image_files.append(image_file)\n",
    "\n",
    "    image_tensors = [plt.imread(image).astype(float) / 255 for image in image_files]\n",
    "    nr_of_images = len(image_tensors)\n",
    "\n",
    "    # print(f\"The first image has label: {label_names[220]}\")\n",
    "    # print(f\"The last image has label: {label_names[nr_of_images - 1]}\")\n",
    "    # print(len(label_names))\n",
    "    # print(len(image_files))\n",
    "\n",
    "    return label_names, image_tensors\n",
    "\n",
    "\n",
    "train_dir = \"C:/Users/Lenovo/MakeAIWork3/Train\"\n",
    "label_names, image_tensors = label_images_in_directories(train_dir)\n",
    "\n",
    "test_dir = \"C:/Users/Lenovo/MakeAIWork3/Test\"\n",
    "label_names, image_tensors = label_images_in_directories(test_dir)\n",
    "\n",
    "\n",
    "# Define the transformations before entering the neural network\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 pixels\n",
    "    transforms.ToTensor(),  # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the images\n",
    "])\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_dataset = ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# display(train_dataset)\n",
    "# print(len(train_dataset))\n",
    "# print(len(test_dataset))\n",
    "\n",
    "# Create DataLoaders for managing the data batches\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define the CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * 56 * 56, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create an instance of the model\n",
    "num_classes = 4\n",
    "model = CNNModel(num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "summary(model.to(device), input_size=(3,224,224))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 16\n",
    "totalLoss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    losses = []\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    train_loss = train_loss / len(train_dataset)\n",
    "    train_acc = train_correct / len(train_dataset)\n",
    "    totalLoss.append(sum(losses)/len(train_dataset))\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_acc = (test_correct / len(test_dataset))*100\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set(xlabel='Epoch', ylabel='Loss', title=\"Training Loss\")\n",
    "\n",
    "plt.plot(totalLoss)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f63566-83db-4804-8c00-71ac1ab67026",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
