{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef91be8-a4c9-4fc4-963e-359d5f6dc4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 224, 224]             448\n",
      "            Conv2d-2         [-1, 32, 112, 112]           4,640\n",
      "            Linear-3                  [-1, 128]      12,845,184\n",
      "            Linear-4                   [-1, 32]           4,128\n",
      "            Linear-5                    [-1, 4]             132\n",
      "           Dropout-6                    [-1, 4]               0\n",
      "================================================================\n",
      "Total params: 12,854,532\n",
      "Trainable params: 12,854,532\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 9.19\n",
      "Params size (MB): 49.04\n",
      "Estimated Total Size (MB): 58.80\n",
      "----------------------------------------------------------------\n",
      "Epoch [1/4], Train Loss: 11.9889, Train Accuracy: 28.27%\n",
      "Epoch [2/4], Train Loss: 1.3860, Train Accuracy: 27.23%\n",
      "Epoch [3/4], Train Loss: 1.3732, Train Accuracy: 32.46%\n",
      "Epoch [4/4], Train Loss: 1.3766, Train Accuracy: 27.23%\n",
      "Test Accuracy: 25.00%\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CNNModel' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 175\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    174\u001b[0m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN_model_apple.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    177\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage Resize\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(image_size)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(image_size),\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBach size\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTeam model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    186\u001b[0m }\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Check if the CSV file already exists\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/miw/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CNNModel' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import os.path\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torchvision.io as io\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, default_collate\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.io import ImageReadMode\n",
    "from torchsummary import summary\n",
    "\n",
    "# use CUDA\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "image_size = 224\n",
    "batch_size = 16\n",
    "num_epochs = 4\n",
    "learning_rate = 0.01\n",
    "num_classes = 4\n",
    "\n",
    "# function for read directury and label images\n",
    "def label_images_in_directories(main_directory):\n",
    "    label_names = []\n",
    "    image_files = []\n",
    "    for directory in os.listdir(main_directory):\n",
    "        sub_directory = os.path.join(main_directory, directory)\n",
    "        if os.path.isdir(sub_directory):\n",
    "            for filename in os.listdir(sub_directory):\n",
    "                image_file = os.path.join(sub_directory, filename)\n",
    "                if os.path.isfile(image_file) and filename.endswith(\".jpg\"):\n",
    "                    label_names.append(directory)\n",
    "                    image_files.append(image_file)\n",
    "\n",
    "    image_tensors = [torchvision.io.read_image(image, mode=ImageReadMode.UNCHANGED).to(torch.float32)/255 for image in image_files]\n",
    "    nr_of_images = len(image_tensors)\n",
    "\n",
    "    return label_names, image_tensors\n",
    "\n",
    "# train_dir = \"./../Project 3/apple_disease_classification/Train_clean_data\"\n",
    "train_dir = \"../data/Train/\"\n",
    "label_names, image_tensors = label_images_in_directories(train_dir)\n",
    "\n",
    "test_dir = \"../data/Test\"\n",
    "label_names, image_tensors = label_images_in_directories(test_dir)\n",
    "\n",
    "# Define the transformations before entering the neural network\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),                     # Resize images to 224x224 pixels\n",
    "    transforms.ToTensor(),                                           # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the images\n",
    "])\n",
    "\n",
    "# Define the transformations before entering the neural network\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=image_size),                                  # Randomly crop and resize images to 224x224 pixels\n",
    "    transforms.RandomHorizontalFlip(),                                              # Randomly flip the images horizontally\n",
    "    transforms.RandomRotation(30),                                                  # Randomly rotate the images by 30 degrees\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Randomly adjust brightness, contrast, saturation, and hue\n",
    "    transforms.ToTensor(),                                                          # Convert images to tensors\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])                 # Normalize the images\n",
    "])\n",
    "\n",
    "# Load the training and test datasets\n",
    "train_dataset = ImageFolder(train_dir, transform=transform_train)\n",
    "test_dataset = ImageFolder(test_dir, transform=transform_test)\n",
    "\n",
    "# Create DataLoaders for managing the data batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes, image_size_nn):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * image_size_nn * image_size_nn, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, num_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        #x = self.fc3(x)\n",
    "        x = self.dropout(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# # Define the CNN model\n",
    "# class CNNModel(nn.Module):\n",
    "#     def __init__(self, num_classes, image_size_nn):\n",
    "#         super(CNNModel, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "#         self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "#         self.fc1 = nn.Linear(32 * image_size_nn**2, 128)\n",
    "#         self.fc2 = nn.Linear(128, 32)\n",
    "#         self.fc3 = nn.Linear(32, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = nn.functional.relu(self.conv1(x))\n",
    "#         x = nn.functional.max_pool2d(x, 2)\n",
    "#         x = nn.functional.relu(self.conv2(x))\n",
    "#         x = nn.functional.max_pool2d(x, 2)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = nn.functional.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "# Create an instance of the model\n",
    "image_size_nn = int(image_size/4)\n",
    "model = CNNModel(num_classes, image_size_nn)\n",
    "model = model.to(device)\n",
    "summary(model.to(device), input_size=(3,image_size,image_size))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "totalLoss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    losses = []\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    train_loss = train_loss / len(train_dataset)\n",
    "    train_acc = (train_correct / len(train_dataset))*100\n",
    "    totalLoss.append(sum(losses)/len(train_dataset))\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_acc = (test_correct / len(test_dataset))*100\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.CNNModel(), \"CNN_model_apple.pth\")\n",
    "\n",
    "data = {\n",
    "    \"Image Resize\": str(image_size)+\"*\"+str(image_size),\n",
    "    \"Bach size\": batch_size,\n",
    "    \"Learning rate\": learning_rate,\n",
    "    \"Epochs\": num_epochs,\n",
    "    \"Train Accuracy\": train_acc,\n",
    "    \"Test Accuracy\": test_acc,\n",
    "    \"Dataset use\": os.path.basename(train_dir),\n",
    "    \"Model type\": \"Team model\"\n",
    "}\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "if os.path.isfile(\"model_data.csv\"):\n",
    "    # Load existing data from CSV\n",
    "    existing_data = pd.read_csv(\"model_data.csv\")\n",
    "    \n",
    "    # Append new data to existing data\n",
    "    new_data = pd.concat([existing_data, pd.DataFrame(data, index=[0])], ignore_index=True)\n",
    "else:\n",
    "    # Create a new DataFrame with the new data\n",
    "    new_data = pd.DataFrame(data, index=[0])\n",
    "\n",
    "# Save the updated DataFrame to CSV\n",
    "new_data.to_csv(\"model_data.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set(xlabel='Epoch', ylabel='Loss', title=\"Training Loss\")\n",
    "\n",
    "plt.plot(totalLoss)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b93ef6d6-f69c-4339-887c-b763b2687b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(CNNModel(num_classes, image_size_nn), \"CNN_model_apple.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8217f5b-2f1f-49ac-a5b7-bdb2998b6b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
