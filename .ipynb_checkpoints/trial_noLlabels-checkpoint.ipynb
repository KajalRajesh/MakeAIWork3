{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a39f27a-0a1a-4935-9752-30f8f2a21e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import os.path\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.cuda as cuda\n",
    "import torchvision.io as io\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, default_collate\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.io import ImageReadMode \n",
    "from torchsummary import summary\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48a77e84-e34c-458c-989b-a1f3ae4c99d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = { \n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "       \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dce815d-4f13-4b6f-a8ee-eaf4bc75bb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 114)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set train and valid directory paths\n",
    "train_directory = 'C:/Users/Lenovo/MakeAIWork3/images/Train1'\n",
    "test_directory = 'C:/Users/Lenovo/MakeAIWork3/images/Test1'\n",
    "# Batch size\n",
    "bs = 32\n",
    "# Number of classes\n",
    "num_classes = 4\n",
    "# Load Data from folders\n",
    "data = {\n",
    "    'train': ImageFolder(root=train_directory, transform=image_transforms['train']),\n",
    "    \n",
    "    'test': ImageFolder(root=test_directory, transform=image_transforms['test'])\n",
    "}\n",
    "# Size of Data, to be used for calculating Average Loss and Accuracy\n",
    "train_data_size = len(data['train'])\n",
    "\n",
    "test_data_size = len(data['test'])\n",
    "# Create iterators for the Data loaded using DataLoader module\n",
    "train_data = DataLoader(data['train'], batch_size=bs, shuffle=True)\n",
    "\n",
    "test_data = DataLoader(data['test'], batch_size=bs, shuffle=True)\n",
    "# Print the train, validation and test set data sizes\n",
    "train_data_size, test_data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "697397ce-b3f3-4472-aa24-91c1a0cbeb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained ResNet50 Model\n",
    "resnet50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b8d50a6-98cc-4be9-a671-cf0afb5b10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze model parameters\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a01105e4-1d04-4d1c-a3e3-a92ed056104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the final layer of ResNet50 Model for Transfer Learning\n",
    "fc_inputs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, 4), \n",
    "    nn.LogSoftmax(dim=1) # For using NLLLoss()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06eaeec6-acbe-429b-948c-67f7cce34dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert model to be used on GPU\n",
    "resnet50 = resnet50.to('cpu')\n",
    "\n",
    "# Define Optimizer and Loss Function\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = optim.Adam(resnet50.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75fd2858-21ce-405d-bd55-b94ea3091b89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mepochs\u001b[49m):\n\u001b[0;32m      2\u001b[0m         epoch_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, epochs))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "epochs =16\n",
    "for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "        # Set to training mode\n",
    "        model.train()\n",
    "        # Loss and Accuracy within the epoch\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        valid_loss = 0.0\n",
    "        valid_acc = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Clean existing gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass - compute outputs on input data using the model\n",
    "            outputs = model(inputs)\n",
    "            # Compute loss\n",
    "            loss = loss_criterion(outputs, labels)\n",
    "            # Backpropagate the gradients\n",
    "            loss.backward()\n",
    "            # Update the parameters\n",
    "            optimizer.step()\n",
    "            # Compute the total loss for the batch and add it to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            # Compute the accuracy\n",
    "            ret, predictions = torch.max(outputs.data, 1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            # Convert correct_counts to float and then compute the mean\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            # Compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "            print(\"Batch number: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}\".format(i, loss.item(), acc.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae11c323-041e-462e-be63-00fef87e0d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation - No gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "            # Set to evaluation mode\n",
    "            model.eval()\n",
    "            # Validation loop\n",
    "            for j, (inputs, labels) in enumerate(valid_data_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # Forward pass - compute outputs on input data using the model\n",
    "                outputs = model(inputs)\n",
    "                # Compute loss\n",
    "                loss = loss_criterion(outputs, labels)\n",
    "                # Compute the total loss for the batch and add it to valid_loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "                # Calculate validation accuracy\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "                # Convert correct_counts to float and then compute the mean\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "                # Compute total accuracy in the whole batch and add to valid_acc\n",
    "                valid_acc += acc.item() * inputs.size(0)\n",
    "                print(\"Validation Batch number: {:03d}, Validation: Loss: {:.4f}, Accuracy: {:.4f}\".format(j, loss.item(), acc.item()))\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size \n",
    "        avg_train_acc = train_acc/float(train_data_size)\n",
    "        # Find average training loss and training accuracy\n",
    "        avg_valid_loss = valid_loss/valid_data_size \n",
    "        avg_valid_acc = valid_acc/float(valid_data_size)\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "        epoch_end = time.time()\n",
    "        print(\"Epoch : {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, nttValidation : Loss : {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc*100, epoch_end-epoch_start))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
