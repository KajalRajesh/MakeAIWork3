{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ad83ef-4ee3-4463-9b5e-127f12237363",
   "metadata": {},
   "source": [
    "<a href=\"https://it-omscholing.nl/locaties/hogeschool-rotterdam/\">\n",
    "<div>\n",
    "<a><img src='../../pics/banner.PNG'/></a>\n",
    "</div>\n",
    "<div>\n",
    "<a href=''><img src='../../pics/miw.PNG'/></a>\n",
    "</div>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf243b00-2d08-48b7-85cf-b9f2c288d81d",
   "metadata": {},
   "source": [
    "# Practicum Convolution Neural Nets (CNN) Deel 1\n",
    "\n",
    "**Doel: Toepassen Convolutional Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0beb08-683b-4d1a-8a3b-7c2938aef74f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f2ed2f-2d11-4d51-a10f-02ff61588ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import ImageReadMode\n",
    "from torchvision.io import read_image\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f9f9b-8024-493f-aa94-b6eb3ad10184",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Globale variabelen</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae222e-fc69-47b6-bb65-ad38f29c38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "forestDirectory = '../../pics/2750/River'\n",
    "industrialDirectory = '../../pics/2750/Industrial'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab893eb4-4667-409f-9f7d-1f2e708be670",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "<p>\n",
    "Dit practicum bestaat uit twee onderdelen\n",
    "<ol>\n",
    "    <li>Het toepassen van een convolutie en pooling filter</li>\n",
    "    <li><b>Het bouwen en trainen van een eenvoudig convolutional neural net dat een industrieterrein van een bos kan onderscheiden.</b></li>\n",
    "</ol>    \n",
    "Voor beide oefeningen gebruiken we de EuroSAT_RGB dataset\n",
    "</p>\n",
    "\n",
    "<img src='../../pics/eurosat_cnn.png' length=65% width=65%>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5305365c-a61c-4dea-adf8-2e9dddef9b82",
   "metadata": {},
   "source": [
    "<h3>Data Collection</h3>\n",
    "<p>\n",
    "We gebruiken Images uit de <a href=\"https://github.com/phelber/EuroSAT\">EuroSat dataset</a> die gemaakt zijn met de Sentinel-2 sateliet. Elke image is een 64x64 pixels foto van Europees aardoppervlak op een hoogte van 10 meter. De images zijn te categoriseren in Highway, Industrial, Pasture, PermanentCrop, Residential, River en SeaLake.\n",
    "</p>\n",
    "<img src=../../pics/eurosat_overview_small.jpg length=40% width=40%>\n",
    "<p>\n",
    "Download <a href=\"http://madm.dfki.de/files/sentinel/EuroSAT.zip\">EuroSAT.zip</a> en kopieer daaruit de directory 2750 naar opdrachten/practica/pics.      \n",
    "<strong>Voeg het pad naar de directory 2750 toe aan .gitignore zodat je de plaatjes niet naar je remote git repository pusht</strong>\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd05422a-e689-4a5d-a513-d347bb4b3b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import ImageReadMode\n",
    "from torchvision.io import read_image\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a9c548-f664-4fd4-a84b-3f8b0e7c118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forestDirectory = '../../pics/2750/Forest'\n",
    "industrialDirectory = '../../pics/2750/Industrial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e08ee-b691-49a0-bffc-41759ba35b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "industrial = torchvision.io.read_image(f'{industrialDirectory}/Industrial_1.jpg', ImageReadMode.GRAY).float()\n",
    "forest = torchvision.io.read_image(f'{forestDirectory}/Forest_1.jpg', ImageReadMode.GRAY).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead098b-7494-436d-8f34-8b30bac5f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting the images\n",
    "def plotImgs(lImg, rImg):\n",
    "    plt.style.use('dark_background') \n",
    "    plt.rcParams[\"font.size\"] = 10\n",
    "    plt.rcParams[\"figure.figsize\"] = (10, 7)\n",
    "\n",
    "    fig, (axL, axR) = plt.subplots(ncols=2, constrained_layout=True)\n",
    "    \n",
    "    imL = axL.imshow(np.squeeze(lImg))\n",
    "    imR = axR.imshow(np.squeeze(rImg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da250e7-2075-411c-b097-6bf232981619",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Opdrachten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0b72b5-c897-46c1-bef7-033a0881f548",
   "metadata": {},
   "source": [
    "### Opdracht 3: pooling uitvoeren\n",
    "\n",
    "Met PyTorch Functional kunnen we ook een pooling filter toepassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a85a20-7ca7-49c2-a309-19044ddd6bf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a. Bekijk de pooling opties en kies de juiste avg-variant\n",
    "\n",
    "#    - Kies een 3x3 kernel en een stride van 1\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "\n",
    "pooling = torch.nn.AvgPool2d(kernel_size, stride=None, padding=0)\n",
    "\n",
    "\n",
    "\n",
    "# b. Pas pooling toe op de afbeelding 'Industrial_1.jpg':\n",
    "\n",
    "\n",
    "industrialPooling = pooling(industrial)\n",
    "\n",
    "\n",
    "\n",
    "# plot image\n",
    "\n",
    "industrialPooling = torch.Tensor.detach(industrialPooling)\n",
    "plotImgs(industrial, industrialPooling)\n",
    "\n",
    "\n",
    "# c. Herhaal de bovenstaande stappen voor een willekeure Forest Image\n",
    "\n",
    "forestPooling = pooling(industrial)\n",
    "\n",
    "#forestFiltered = poolFilter(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8106782-6130-46c4-98b2-f726a8d5d9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5294c9-fbd4-4500-8bc4-dc20f300d052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36a09543-15ad-4222-9051-5aa536955c3b",
   "metadata": {},
   "source": [
    "### Reflectie\n",
    "\n",
    "Komt de visuele uitkomst overeen met je verwachtingen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75fe4ef-1016-4e0a-8657-8b662c58cc92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extra: varieer de stride en de kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b93dbb9-53e0-4afa-b83b-70028c73f30f",
   "metadata": {},
   "source": [
    "### Reflectie\n",
    "\n",
    "Wat is de invloed van padding en stride op de uitkomst?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2054047a-79ca-4fe0-bd17-2de8ded73320",
   "metadata": {},
   "source": [
    "### Opdracht 4: convolutie en pooling combineren\n",
    "\n",
    "Een convolutional neural net combineert afwisselend convolutie en pooling in de eerste lagen.\n",
    "\n",
    "We kunnen nu het effect van deze combinatie onderzoeken:\n",
    "\n",
    "- Convolutie\n",
    "- Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0266c837-6e9b-4e43-9537-bc576e45df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Bedenk en maak zelf een 2d convolution filter\n",
    "\n",
    "\n",
    "convFilter = torch.nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=0)\n",
    "\n",
    "# b. Bedenk en maak zelf een 2d pooling filter\n",
    "\n",
    "poolFilter1 = torch.nn.MaxPool2d(kernel_size = 3, stride=1, padding=0)\n",
    "\n",
    "# c. Pas nu de convolutie toe op 'Industrial_1.jpg'\n",
    "\n",
    "industrialConvFilter = convFilter(industrial)\n",
    "\n",
    "# d. Pas vervolgens een pooling toe op de uitkomst van c.\n",
    "pooledIndustrialOutput = poolFilter1(industrialConvFilter)\n",
    "\n",
    "# e. Doe hetzelfde voor de afbeelding 'Forrest_1.jpg'\n",
    "\n",
    "forestConvFilter = convFilter(forest)\n",
    "pooledForestOutput = poolFilter1(forestConvFilter)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85654aa-c790-4139-b73c-581612726ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oplossing\n",
    "# Squeeze and detach to plot image.\n",
    "pooledIndustrialOutput = torch.Tensor.detach(pooledIndustrialOutput)\n",
    "plotImgs(industrial, pooledIndustrialOutput)\n",
    "\n",
    "pooledForestOutput = torch.Tensor.detach(pooledForestOutput)\n",
    "plotImgs(forest, pooledForestOutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d444bfc7-3460-427d-b6a3-2f498ef2813e",
   "metadata": {},
   "source": [
    "### Reflectie\n",
    "\n",
    "- Verschilt de uitkomst veel van de combinatie veel met convolutie en pooling?\n",
    "- En zijn de afbeeldingen 'Industrial_1.jpg' en 'Forrest_1.jpg' beter te onderscheiden?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43c29fd-3908-4d3b-8cb3-694f8c717c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra: bereid de combinatie uit met nog een extra convolutie en pooling laag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8243671-21a0-45b2-883a-6c9ab35756f1",
   "metadata": {},
   "source": [
    "### Reflectie\n",
    "\n",
    "Heeft een extra laag veel invloed op de onderscheidbaarheid van de afbeeldingen?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd748ec9-c052-43ba-8a7f-110e47542d92",
   "metadata": {},
   "source": [
    "### Opdracht 5: dataset prepareren\n",
    "\n",
    "Om het neurale netwerk te trainen moeten we de dataset opsplitsen in labels (Y, de categoriën) en input afbeeldingen (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563c265-e471-4f8b-a388-4da8229c5067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a. Denk nog eens terug aan hoe we kruisjes van rondjes van elkaar konden onderscheiden\n",
    "listOfFileNames = []\n",
    "outputLabels = []\n",
    "\n",
    "for filename in os.listdir(industrialDirectory):\n",
    "    imgFile = os.path.join(industrialDirectory, filename)\n",
    "\n",
    "    if \".jpg\" in imgFile:\n",
    "        listOfFileNames.append(imgFile)\n",
    "        outputLabels.append([0,1])\n",
    "        \n",
    "for filename in os.listdir(forestDirectory):\n",
    "    imgFile = os.path.join(forestDirectory, filename)\n",
    "\n",
    "    if \".jpg\" in imgFile:\n",
    "        listOfFileNames.append(imgFile)\n",
    "        outputLabels.append([1,0])\n",
    "        \n",
    "display(len(outputLabels))\n",
    "\n",
    "\n",
    "# b. Hoe kunnen we de labels 'Industrials' en 'Forrest' dus representeren?\n",
    "\n",
    "# c. Vorm nu een dataset voor 'Industrials' en 'Forrest'\n",
    "\n",
    "# d. Extra: implementeer bovenstaande via een Dataset en DataLoader class\n",
    "#           (zie https://pytorch.org/docs/stable/data.html voor verdere details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fdcff4-2eda-4d01-8835-0e40131697bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "for images in listOfFileNames:\n",
    "    \n",
    "\n",
    "convert_tensor = transforms.ToTensor()\n",
    "convert_tensor(listOfFileNames)\n",
    "display(convert_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dd0ad8-90bd-42c3-8fc8-653ac6059c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageTensors = trans[ plt.imread(pic).astype(float) for pic in listOfFileNames ]\n",
    "nrOfImages = len(imageTensors)\n",
    "display(imageTensors)\n",
    "outputLabelArray = np.asarray(outputLabels)\n",
    "\n",
    "\n",
    "full_dataset = []\n",
    "for i in range(len(imageTensors)):\n",
    "    full_dataset.append([imageTensors[i], outputLabelsArray[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213813ff-a44d-427f-bb16-661673e8a333",
   "metadata": {},
   "source": [
    "### Opdracht 6: CNN ontwerpen\n",
    "\n",
    "We kunnen een convolutional neural net opbouwen met convolutie, pooling en fully connected lagen. Hieronder definiëren we een topologie om een afbeeldingen van 32 x 32 te onderscheiden.\n",
    "\n",
    "De topologie is gebaseerd op de blog post 'A simple CNN with Pytorch'. Dus zie het artikel voor extra details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a84b2a-3058-459d-8fb5-3fe8d0a7b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    #-------------------------------------------------------\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # Because we inherit from Module base class\n",
    "        super().__init__()\n",
    "        \n",
    "        # RGB input, 6 filters, kernel of 5 x 5\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        \n",
    "        # Filter is 2 x 2 with a stride of 2 (defined once, used two times)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # in_channels = 6 because self.conv1 output has 6 channels\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # Fully connected layer matched on output of conv2 layer\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        \n",
    "        # We only have 2 labels\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "        \n",
    "    #-------------------------------------------------------\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Convolution with relu layers\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # To match the output of the conv2 layer onto the first fully connected layer\n",
    "        # Like reshape() but makes no copy (reuses underlaying data)\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # No activation on final layer \n",
    "        return self.fc3(x)\n",
    "\n",
    "#-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3248f8b9-64b2-4cf4-ab9f-bcc74c8076db",
   "metadata": {},
   "source": [
    "### Opdracht 7: CNN trainen\n",
    "\n",
    "Het trainen van een CNN is identiek aan het trainen van een fully connected (a.k.a. dense) netwerk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a64e93d-e9e2-49d3-b047-20afb4887f2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a. Ga voor jezelf na welke stappen een typisch trainingsproces bevat\n",
    "\n",
    "# b. Bekijk de blog post 'A simple CNN in Python' en zet de training op\n",
    "\n",
    "# c. Het voorbeeld bevat geen validatie tijdens de trainingsstap (epoch)\n",
    "\n",
    "#    - Bekijk het Notebook met de de postcode FastScan\n",
    "#      en bereid de training uit met validatie in de trainingsloop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503bc56-46d6-4e15-8d91-d7784edc5e2b",
   "metadata": {},
   "source": [
    "### Opdracht 8: dropout toevoegen\n",
    "\n",
    "Om het netwerk effectiever te trainen wordt dropout toegepast.\n",
    "\n",
    "PyTorch maakt het toevoegen van dropout makkelijk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d98c7a-3358-4937-8bc0-fd8b003121c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a. Bekijk het artikel Using Dropout Regularization in PyTorch Models (zie sources)\n",
    "\n",
    "# b. Pas nu dropout toe op een hidden layer van je model\n",
    "\n",
    "# c. Hertrain je model\n",
    "\n",
    "#    - Let er op dat je je model evalueert in eval() mode\n",
    "#    - Heeft de dropout invloed op de accuracy van je model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91aa1cc-60c9-481b-9d66-3ab359b7422a",
   "metadata": {},
   "source": [
    "### Reflectie\n",
    "\n",
    "- Wat gebeurt er als de dropout groot is (bijvoobeeld 0.9)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b682a804-e1f7-4b9d-a3fe-2de933c32f44",
   "metadata": {},
   "source": [
    "### Bronnen\n",
    "\n",
    "[EuroSAT project](https://github.com/phelber/eurosat)\n",
    "\n",
    "[Pytorch Neural Nets](https://pytorch.org/docs/stable/nn.html)\n",
    "\n",
    "[Kernels](https://en.wikipedia.org/wiki/Kernel_(image_processing))\n",
    "\n",
    "[A simple CNN with Pytorch](https://tomroth.com.au/pytorch-cnn)\n",
    "\n",
    "[A guide to convolution arithmetic for deep learning](https://arxiv.org/pdf/1603.07285.pdf)\n",
    "\n",
    "[Using Dropout Regularization in PyTorch Models](https://machinelearningmastery.com/using-dropout-regularization-in-pytorch-models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
