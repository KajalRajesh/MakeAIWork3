{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683e8b5d-8408-4aa4-b0ca-f54f480bcd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. Extra: implementeer bovenstaande via een Dataset en DataLoader class\n",
    "#           (zie https://pytorch.org/docs/stable/data.html voor verdere details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba3c02-e3d7-4076-8751-3fc8ac98d3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imageTensors = [ plt.imread(pic).astype(np.float32) for pic in listOfFileNames ]\n",
    "# eigenlijk zijn dit geen Tensors maar np arrays die via een transpose in de goede volgorde worden geplaatst!\n",
    "\n",
    "# imageTensors = [ plt.imread(pic).astype(np.float32).transpose(-1, 0, 1) / 255. for pic in listOfFileNames ]\n",
    "# nrOfImages = len(imageTensors)\n",
    "\n",
    "# imageTensors = [ plt.imread(pic).astype(np.float32).transpose(-1, 0, 1) / 255. for pic in listOfFileNames ]\n",
    "# torchvision.io.read_image(image_path, mode=ImageReadMode.UNCHANGED).to(torch.float32)\n",
    "\n",
    "\n",
    "# type(imageTensors)\n",
    "# outputLabelsArray = np.asarray(outputLabels)\n",
    "\n",
    "\n",
    "# full_dataset = []\n",
    "# for i in range(len(imageTensors)):\n",
    "#    full_dataset.append([imageTensors[i], outputLabelsArray[i]])\n",
    "\n",
    "\n",
    "# print(imageTensors[0].shape)\n",
    "# print(type(imageTensors[0]))\n",
    "# print(full_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245f1d4-9ea3-4516-a6fd-60810577024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aantal experimenten op andere manieren "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f20ab5-c80b-4244-829d-fe61f7d36850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatief 1: gebruik utils.data.Tensordataset om er direct Tensors van te maken\n",
    "# deze methode gaf foutmeldingen en is daarom niet verder uitgewerkt\n",
    "\n",
    "# import torch.utils.data as data_utils\n",
    "\n",
    "# dataset = data_utils.TensorDataset(train_feat, train_labels)\n",
    "# train_loader = data_utils.DataLoader(dataset, batch_size=7, shuffle=True)\n",
    "\n",
    "# dataset = data_utils.TensorDataset(imageTensors, outputLabels)\n",
    "# train_loader = data_utils.DataLoader(dataset, batch_size=7, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4999d2-a189-4de9-b1e1-f4257a768999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # alternatief 2: \n",
    "\n",
    "# # create the dataset class\n",
    "# class LandDataset(Dataset):\n",
    "#     def __init__(self, directory, Label):\n",
    "#         self.data = self.load_images(directory)\n",
    "#         self.labels = [Label] * len(self.data) # Assigning the same label (0) to all industrial images\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "#     def __getitem__(self, index):\n",
    "#         image = self.data[index]\n",
    "#         label = self.labels[index]\n",
    "#         return image, label\n",
    " \n",
    "#     def load_images(self, directory):\n",
    "#         image_files = self.listdir(directory)\n",
    "#         data = []\n",
    "#         for file in image_files:\n",
    "#             image_path = path.join(directory, file)\n",
    "#             image = torchvision.io.read_image(image_path, mode=ImageReadMode.UNCHANGED).to(torch.float32)\n",
    "#             data.append(image)\n",
    "#             return data\n",
    "\n",
    " \n",
    " \n",
    "\n",
    "# # use the class to create a set for both types, from the 'global directories, add the labels\n",
    "# forestDataset = LandDataset(forestDirectory, [0,1])\n",
    "# industrialDataset = LandDataset(industrialDirectory, [1,0])\n",
    "# # Concatenate the datasets into a single dataset\n",
    "# dataset = torch.utils.data.ConcatDataset([forestDataset, industrialDataset])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a491fbe3-fbee-48c2-b8bc-f9eeaa5f6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatief 3:\n",
    "\n",
    "# from torchvision.datasets import ImageFolder \n",
    "# The ImageFolder class in torchvision expects the data to be organized in separate folders,\n",
    "# where each folder represents a different class\n",
    "\n",
    " \n",
    "\n",
    "# dataset_path = \"./data/EuroSat/\"\n",
    "# transform = ToTensor()\n",
    "# dataset = ImageFolder(dataset_path, transform=transform)\n",
    "\n",
    " \n",
    "\n",
    "# dataset.class_to_idx\n",
    "\n",
    " \n",
    "\n",
    "# forest_industrial_dataset = torch.utils.data.Subset(dataset, [1,4])\n",
    "\n",
    "# https://pytorch.org/vision/stable/generated/torchvision.datasets.ImageFolder.html?highlight=imagefolder#torchvision.datasets.ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8910c2-5f92-48e3-9cc8-d8ab1e105bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
